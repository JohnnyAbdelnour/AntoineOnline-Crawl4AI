# E-commerce Crawler

This script uses `crawl4ai` to crawl an e-commerce website and store the content in a Supabase table.

## Supabase Setup

You will need a Supabase project to store the crawled data.

1.  Create a new project on [Supabase](https://supabase.com/).
2.  In your project, go to the "SQL Editor" and run the following query to create the `Data` table:

```sql
CREATE TABLE "Data" (
    id bigint generated by default as identity primary key,
    url text,
    content text,
    created_at timestamp with time zone default now()
);
```

## Running the Crawler

1.  Clone this repository.
2.  Install the dependencies: `pip install -r requirements.txt`
3.  Create a `.env` file by copying the `.env.example` file: `cp .env.example .env`
4.  Fill in the required values in the `.env` file.
5.  Run the crawler: `python ecommerce_crawler.py`