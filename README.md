# E-commerce Product Extractor

This script uses `crawl4ai` to crawl an e-commerce website, extract structured product information, and store it in a Supabase table.

## Supabase Setup

You will need a Supabase project to store the crawled data.

1.  Create a new project on [Supabase](https://supabase.com/).
2.  In your project, go to the "SQL Editor" and run the following query to create the `products` table:

```sql
CREATE TABLE "products" (
    id bigint generated by default as identity primary key,
    url text,
    name text,
    price float,
    description text,
    sku text,
    image_url text,
    created_at timestamp with time zone default now()
);
```

## Running the Crawler

1.  Clone this repository.
2.  Install the dependencies: `pip install -r requirements.txt`
3.  Create a `.env` file by copying the `.env.example` file: `cp .env.example .env`
4.  Fill in the required values in the `.env` file, including your OpenAI API key for LLM-based extraction.
5.  Run the crawler: `python ecommerce_crawler.py`